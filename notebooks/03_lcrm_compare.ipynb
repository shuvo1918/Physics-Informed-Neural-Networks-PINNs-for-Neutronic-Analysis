{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.6556e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.2823e-10, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.8193e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.5117e-10, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.9973e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.2429e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.2518e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.6383e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.9918e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.5593e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.2466e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.1708e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.1804e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.5729e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.3404e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.5948e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.0176e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.3123e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.5543e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.7276e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.0429e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.8509e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9884e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4352e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5951e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.8250e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.4867e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.4980e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.5711e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.8084e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.9383e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.7807e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.6209e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.6461e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.6275e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.3665e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.4684e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.3998e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.8902e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.3487e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.3404e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.9999e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.1206e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.2806e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.0836e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.1442e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.5130e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.8543e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.9516e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.0640e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.9836e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.8250e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.0589e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.5311e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.6734e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.9236e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.0146e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.8295e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4405e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.3758e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.5685e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0480e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.1396e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.0936e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.7677e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.2239e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.3655e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0792e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.3508e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.2176e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.6000e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.9817e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.2291e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.0331e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.2615e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.4406e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.9557e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.7859e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.9246e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0761e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.1848e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.1281e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.6532e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.8563e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.0734e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.0369e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.2361e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.0890e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.3899e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.3776e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.4670e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.2715e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.0914e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.2537e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.0185e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.9660e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.9295e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.4567e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.4674e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.7684e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.4365e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.4724e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.6859e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.6614e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.9453e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.4333e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.1084e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.9014e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.9710e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6586e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.9398e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.4569e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.9911e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.5477e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.5921e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.0025e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.5551e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.2412e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.4100e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.4029e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.7421e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.1663e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.8331e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.3168e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.8553e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.2225e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.3779e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.2509e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.4520e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.8698e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.1486e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.2038e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.4551e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3290e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.3070e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.2838e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.5121e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.8411e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.9518e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.9080e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.1432e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.1861e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.0804e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.2867e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.3899e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1337e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.4886e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.4204e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.0770e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.2470e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.5680e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(9.1198e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.0485e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.2929e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.5919e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.0085e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.9067e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.2806e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.7635e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.7256e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.7837e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.7987e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.8617e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.8415e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(7.9026e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.6346e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.2375e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.8451e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.5955e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.1950e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.2888e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.7288e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.1800e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.2685e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.3441e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8743e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.3349e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.7667e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.8160e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.1337e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.2128e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.8871e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.1933e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.6420e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.2988e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.8060e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.8485e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.9118e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.1481e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.9180e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.7610e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.6539e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.8341e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.0883e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.2960e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.5155e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.0456e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.5181e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.5471e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(4.4295e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.9407e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.3405e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.5693e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.3755e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.6395e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(7.7837e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.5753e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.6095e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.2731e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.1556e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.2555e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.5249e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.9070e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.8610e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.9348e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.7934e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.9119e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(3.4815e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.1590e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.4659e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.1009e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.6233e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.9774e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3669e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9402e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.1640e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.0817e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.4961e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.6603e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(6.1171e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.4614e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.7817e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.8981e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.3722e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.4066e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1608e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.4045e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.8104e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.2050e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.2930e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.4288e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.1560e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.8305e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.9190e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.7586e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.2341e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.2904e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.7031e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.2252e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.2239e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(6.3886e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.1336e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.2490e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(5.9963e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.4583e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.5615e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.8889e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.0674e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.2397e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(8.7929e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.7564e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.1425e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.0122e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.9894e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.1473e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(1.6679e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.4964e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(3.7677e-09, device='cuda:0', grad_fn=<MeanBackward0>) tensor(2.0108e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.9102e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.9807e-06, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')                     #This is for using AGG backend in order to prevent failure of memory while creating the images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(torch.cuda.get_device_name())\n",
    "class FCN(nn.Module):\n",
    "    \"Defines a fully-connected network in PyTorch\"\n",
    "    def __init__(self,N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x\n",
    "def materials(x,y):\n",
    "    d_blanket=torch.add(torch.zeros_like(x),2.094999864)\n",
    "    d_core = torch.add(torch.zeros_like(x),2.200801092)\n",
    "    s_blanket= torch.add(torch.zeros_like(x),0.00214231)\n",
    "    s_core= torch.add(torch.zeros_like(x),0.01048083)\n",
    "    sigma_a_blanket=torch.add(torch.zeros_like(x),0.064256)\n",
    "    sigma_a_core =torch.add(torch.zeros_like(x),0.062158)\n",
    "    sigma_s_blanket= torch.add(torch.zeros_like(x),0.094853)\n",
    "    sigma_s_core= torch.add(torch.zeros_like(x),0.089302)\n",
    "    c1= ((x >= 10) & (x <= 30)) & ((y >= 10) & (y <= 30))\n",
    "    c2= (x >= 70) & (x <= 90) & (y >= 70) & (y <= 90)\n",
    "    region= c1|c2\n",
    "    d=torch.where(region,d_core,d_blanket)\n",
    "    s=torch.where(region,s_core,s_blanket)\n",
    "    sigma_a=torch.where(region,sigma_a_core,sigma_a_blanket)\n",
    "    sigma_s=torch.where(region,sigma_s_core,sigma_a_blanket)\n",
    "\n",
    "    return d, s, sigma_a,sigma_s\n",
    "\n",
    "N_b=1000\n",
    "N_f=3000\n",
    "#Test_point=1000\n",
    "\n",
    "X_lb = np.array([0.0, 0.0]) + np.array([100.0, 0.0]) * lhs(2,  int(N_b))\n",
    "X_ub = np.array([0.0, 100.0]) + np.array([100.0, 0.0]) * lhs(2,  int(N_b))\n",
    "Y_lb = np.array([0.0, 0.0]) + np.array([0.0, 100.0]) * lhs(2,  int(N_b))\n",
    "Y_rb = np.array([100.0, 0.0]) + np.array([0.0, 100.0]) * lhs(2,  int(N_b))\n",
    "X_f  = np.array([0.0,0.0])+ np.array([100.0,100.0])*lhs(2,int(N_f))\n",
    "X_test = np.array([0.0,0.0])+ np.array([100.0,100.0])*lhs(2,int(Test_point))\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "pinn= FCN(2,1,40,8).to(device)\n",
    "lower=torch.tensor(X_lb, dtype=torch.float32, requires_grad=True).to(device)\n",
    "upper=torch.tensor(X_ub, dtype=torch.float32, requires_grad=True).to(device)\n",
    "left = torch.tensor(Y_lb, dtype=torch.float32, requires_grad=True).to(device)\n",
    "right=torch.tensor(Y_rb, dtype=torch.float32, requires_grad=True).to(device)\n",
    "train=torch.tensor(X_f, dtype=torch.float32, requires_grad=True).to(device)\n",
    "d,s,sig_a,sig_s=materials(train[:,0],train[:,1])\n",
    "d=d.to(device)\n",
    "s=s.to(device)\n",
    "sig_a=sig_a.to(device)\n",
    "sig_s=sig_s.to(device)\n",
    "#test=torch.tensor(X_test,dtype=torch.float32)\n",
    "x=np.linspace(0,100,100)\n",
    "y=np.linspace(0,100,100)\n",
    "X,Y= np.meshgrid(x,y)\n",
    "test= torch.tensor(np.vstack([X.flatten(), Y.flatten()]).T, dtype=torch.float32).cpu()\n",
    "test=test.to(device)\n",
    "optimiser= torch.optim.Adam(pinn.parameters(),lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimiser, step_size=2000, gamma=0.95)\n",
    "# Early Stopping and Training Loop\n",
    "best_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "early_stopping_patience = 10\n",
    "\n",
    "plot_dir = '60_8_1000_3000_1000_test_45000steps_d_age'\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "for i in range(45001):\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    u=pinn(lower)\n",
    "    dudy=torch.autograd.grad(u,lower,torch.ones_like(u),create_graph=True)[0]\n",
    "    loss_low=torch.mean((.5*u-(2.094999864*dudy[:,[1]]))**2)\n",
    "    u=pinn(upper)\n",
    "    dudy=torch.autograd.grad(u,upper,torch.ones_like(u),create_graph=True)[0]\n",
    "    loss_ub=torch.mean((.5*u+(2.094999864*dudy[:,[1]]))**2)\n",
    "    u=pinn(left)\n",
    "    dudx=torch.autograd.grad(u,left,torch.ones_like(u),create_graph=True)[0]\n",
    "    loss_lb=torch.mean((.5*u-(2.094999864*dudx[:,[0]]))**2)\n",
    "    u=pinn(right)\n",
    "    dudx=torch.autograd.grad(u,right,torch.ones_like(u),create_graph=True)[0]\n",
    "    loss_rb=torch.mean((.5*u+(2.094999864*dudx[:,[0]]))**2)\n",
    "    #define Physics loss\n",
    "    # Compute the gradient (first derivatives) of u with respect to x and y\n",
    "    u=pinn(train)\n",
    "    grad_u= torch.autograd.grad(u,train,torch.ones_like(u),create_graph=True)[0]\n",
    "    grad_u_x = d*grad_u[:,0]\n",
    "    grad_u_y = d*grad_u[:,1]\n",
    "\n",
    "# Now we need to compute the second derivatives\n",
    "    grad_u_xx=torch.autograd.grad(grad_u_x, train, grad_outputs=torch.ones_like(grad_u_x), create_graph=True)[0]\n",
    "    grad_u_yy=torch.autograd.grad(grad_u_y, train, grad_outputs=torch.ones_like(grad_u_y), create_graph=True)[0]\n",
    "    d2u_dx2 =grad_u_xx[:,0]   # Second derivative with respect to x\n",
    "    d2u_dy2 = grad_u_yy[:,1]  # Second derivative with respect to y\n",
    "    loss_phy=torch.mean((-s-(d2u_dx2+d2u_dy2)+(sig_a*u))**2)\n",
    "    loss=loss_low+loss_ub+loss_lb+loss_rb+loss_phy\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if i %1000==0:\n",
    "        #print(test.shape)\n",
    "        phi=pinn(test).detach().cpu()\n",
    "        phid=phi.view(X.shape)\n",
    "        print(loss_low,loss_ub, loss_lb , loss_rb,loss_phy,loss)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        #phi=phi.reshape(len(x),len(x))\n",
    "        surf = ax.plot_surface(X,Y,phid,cmap='viridis')\n",
    "        # Add labels and title\n",
    "        ax.set_xlabel('X-axis')\n",
    "        ax.set_ylabel('Y-axis')\n",
    "        ax.set_zlabel('Flux')\n",
    "        ax.set_title(f'Training Step{i}')\n",
    "    \n",
    "\n",
    "        # Add colorbar\n",
    "        fig.colorbar(surf, ax=ax, label='Flux')\n",
    "        fig.savefig(os.path.join(plot_dir, f'plot_epoch_{i}.png'))\n",
    "        \n",
    "\n",
    "        # Show the plot\n",
    "        #plt.show()\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.contourf(X,Y,phid, levels=100)\n",
    "        plt.colorbar()\n",
    "        #plt.title('Neutron Flux')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.title(f'Training Step {i}')\n",
    "        plt.savefig(os.path.join(plot_dir, f'plot_epoch_heat{i}.png'))\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            early_stop_counter = 0\n",
    "            # Saving the model state\n",
    "            torch.save(pinn, os.path.join(plot_dir, f'pinn_model_step_{i}.pth'))\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= early_stopping_patience:\n",
    "                print(f\"Stopping early at step {i}\")\n",
    "                continue\n",
    "\n",
    "torch.save(pinn, os.path.join(plot_dir, 'final_pinn_model_best.pth'))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(pinn, os.path.join(plot_dir, '/final_pinn_model_full.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing And Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./40_8_1000_5000_1000_test/final_pinn_model_full.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "model=torch.load('./40_8_1000_5000_1000_test/final_pinn_model_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.6396e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(1.4505e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(4.2022e-07, device='cuda:0', grad_fn=<MeanBackward0>) tensor(5.8596e-08, device='cuda:0', grad_fn=<MeanBackward0>) tensor(8.4593e-06, device='cuda:0', grad_fn=<MeanBackward0>) tensor(9.0090e-06, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[-5.2832e-04, -5.7699e-04, -5.6263e-04,  ..., -7.1064e-05,\n",
      "         -1.2806e-04, -1.8538e-04],\n",
      "        [-3.0377e-04, -3.0778e-04, -3.2734e-04,  ..., -3.6456e-05,\n",
      "         -1.0172e-04, -1.6698e-04],\n",
      "        [-8.2240e-05, -2.7530e-06,  4.5642e-05,  ...,  6.6876e-05,\n",
      "         -1.1008e-05, -8.8502e-05],\n",
      "        ...,\n",
      "        [ 3.6534e-04,  5.3443e-04,  6.8678e-04,  ...,  1.4722e-03,\n",
      "          1.4392e-03,  1.4111e-03],\n",
      "        [ 3.2083e-04,  4.8183e-04,  6.2523e-04,  ...,  1.3724e-03,\n",
      "          1.3362e-03,  1.3089e-03],\n",
      "        [ 2.7863e-04,  4.3214e-04,  5.6734e-04,  ...,  1.2742e-03,\n",
      "          1.2405e-03,  1.2096e-03]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_49524\\3874817862.py:23: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "phi=model(test).detach().cpu()\n",
    "phid=phi.view(X.shape)\n",
    "print(loss_low,loss_ub, loss_lb , loss_rb,loss_phy,loss)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "#phi=phi.reshape(len(x),len(x))\n",
    "surf = ax.plot_surface(X,Y,phid,cmap='viridis')\n",
    "# Add labels and title\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Flux')\n",
    "ax.set_title(f'Training Step{i}')\n",
    "\n",
    "\n",
    "# Add colorbar\n",
    "fig.colorbar(surf, ax=ax, label='Flux')\n",
    "fig.savefig(os.path.join(plot_dir, f'plot_epoch_{i}.png'))\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "print(phid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')                     #This is for using AGG backend in order to prevent failure of memory while creating the images\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(torch.cuda.get_device_name())\n",
    "class FCN(nn.Module):\n",
    "    \"Defines a fully-connected network in PyTorch\"\n",
    "    def __init__(self,N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()])\n",
    "        self.fch = nn.Sequential(*[\n",
    "                        nn.Sequential(*[\n",
    "                            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                            activation()]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        x = self.fch(x)\n",
    "        x = self.fce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.000218194610140953\n",
      "Relative Error: 0.37470449966484715\n",
      "Relative Percentage Error: 32.40195869938062%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load the trained PINN model (make sure to replace this with the correct path to your saved model)\n",
    "pinn_model_path = './40_8_1000_5000_1000_test_35000steps_d_age/final_pinn_model_best.pth'\n",
    "pinn_model = torch.load(pinn_model_path, map_location=device)\n",
    "\n",
    "# Load the FEM results from the CSV file\n",
    "fem_results = pd.read_csv('./LCRM_sol.csv')\n",
    "\n",
    "num_points = len(fem_results)\n",
    "x = np.linspace(0, 100, num_points)\n",
    "y = np.linspace(0, 100, num_points)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Flatten the meshgrid coordinates and FEM results for comparison\n",
    "X_flat = X.flatten()\n",
    "Y_flat = Y.flatten()\n",
    "U_fem_flat = fem_results.values.flatten()\n",
    "X_fem_tensor = torch.tensor(np.vstack([X_flat, Y_flat]).T, dtype=torch.float32).to(device)\n",
    "# # Convert to tensor\n",
    "# X_fem_tensor = torch.tensor(X_fem, dtype=torch.float32).to(device)\n",
    "# Generate PINN predictions\n",
    "pinn_model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    U_pinn = pinn_model(X_fem_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# Calculate MSE\n",
    "mse_error = ((U_pinn - U_fem_flat) ** 2).mean()\n",
    "print(f'Mean Squared Error: {mse_error}')\n",
    "\n",
    "# Calculate the relative error\n",
    "relative_error = np.sqrt(mse_error) / np.abs(U_fem_flat).mean()\n",
    "print(f'Relative Error: {relative_error}')\n",
    "# Calculate the relative percentage error\n",
    "relative_percentage_error = (np.linalg.norm(U_pinn - U_fem_flat) / np.linalg.norm(U_fem_flat)) * 100\n",
    "\n",
    "print(f'Relative Percentage Error: {relative_percentage_error}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00524517]\n",
      " [0.00604459]\n",
      " [0.00664264]\n",
      " ...\n",
      " [0.00405727]\n",
      " [0.00350349]\n",
      " [0.00286959]]\n"
     ]
    }
   ],
   "source": [
    "print(pinn_model(X_fem_tensor).detach().cpu().numpy())\n",
    "point_df=pd.DataFrame(pinn_model(X_fem_tensor).detach().cpu().numpy())\n",
    "point_df.to_csv('model_pred_index.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0002259812871847695\n",
      "Relative Error: 0.38133190075884765\n",
      "Relative Percentage Error: 32.97505236845614%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load the trained PINN model (make sure to replace this with the correct path to your saved model)\n",
    "pinn_model_path = './40_8_1000_5000_1000_test_35000steps/final_pinn_model_best.pth'\n",
    "pinn_model = torch.load(pinn_model_path, map_location=device)\n",
    "\n",
    "# Load the FEM results from the CSV file\n",
    "fem_results = pd.read_csv('./LCRM_sol.csv')\n",
    "\n",
    "num_points = len(fem_results)\n",
    "x = np.linspace(0, 100, num_points)\n",
    "y = np.linspace(0, 100, num_points)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Flatten the meshgrid coordinates and FEM results for comparison\n",
    "X_flat = X.flatten()\n",
    "Y_flat = Y.flatten()\n",
    "U_fem_flat = fem_results.values.flatten()\n",
    "X_fem_tensor = torch.tensor(np.vstack([X_flat, Y_flat]).T, dtype=torch.float32).to(device)\n",
    "# # Convert to tensor\n",
    "# X_fem_tensor = torch.tensor(X_fem, dtype=torch.float32).to(device)\n",
    "# Generate PINN predictions\n",
    "pinn_model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    U_pinn = pinn_model(X_fem_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# Calculate MSE\n",
    "mse_error = ((U_pinn - U_fem_flat) ** 2).mean()\n",
    "print(f'Mean Squared Error: {mse_error}')\n",
    "\n",
    "# Calculate the relative error\n",
    "relative_error = np.sqrt(mse_error) / np.abs(U_fem_flat).mean()\n",
    "print(f'Relative Error: {relative_error}')\n",
    "# Calculate the relative percentage error\n",
    "relative_percentage_error = (np.linalg.norm(U_pinn - U_fem_flat) / np.linalg.norm(U_fem_flat)) * 100\n",
    "\n",
    "print(f'Relative Percentage Error: {relative_percentage_error}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'best'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(pinn_models_dir)):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 34\u001b[0m         step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Extract step number from filename\u001b[39;00m\n\u001b[0;32m     35\u001b[0m         pinn_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pinn_models_dir, filename)\n\u001b[0;32m     36\u001b[0m         pinn_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(pinn_model_path, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'best'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the FEM results from the CSV file\n",
    "fem_results_path = './LCRM_sol.csv'\n",
    "fem_results = pd.read_csv(fem_results_path)\n",
    "\n",
    "# Flatten the FEM results for comparison\n",
    "U_fem_flat = fem_results.values.flatten()\n",
    "\n",
    "# Generate the meshgrid for the domain\n",
    "num_points = int(np.sqrt(len(U_fem_flat)))  # Assuming a square domain\n",
    "x = np.linspace(0, 100, num_points)\n",
    "y = np.linspace(0, 100, num_points)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "X_flat = X.flatten()\n",
    "Y_flat = Y.flatten()\n",
    "X_fem_tensor = torch.tensor(np.vstack([X_flat, Y_flat]).T, dtype=torch.float32).to(device)\n",
    "\n",
    "# Directory where the PINN models are saved\n",
    "pinn_models_dir = './40_8_1000_5000_1000_test_70000steps/stages/'\n",
    "\n",
    "# Initialize a DataFrame to store the errors\n",
    "error_df = pd.DataFrame(columns=['Step', 'MSE', 'Relative_Error', 'Relative_Percentage_Error'])\n",
    "\n",
    "# Loop through the saved models and calculate errors\n",
    "for filename in sorted(os.listdir(pinn_models_dir)):\n",
    "    if filename.endswith('.pth'):\n",
    "        step = int(filename.split('_')[-1].split('.')[0])  # Extract step number from filename\n",
    "        pinn_model_path = os.path.join(pinn_models_dir, filename)\n",
    "        pinn_model = torch.load(pinn_model_path, map_location=device)\n",
    "        pinn_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            U_pinn = pinn_model(X_fem_tensor).cpu().numpy().flatten()\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse_error = ((U_pinn - U_fem_flat) ** 2).mean()\n",
    "\n",
    "        # Calculate the relative error\n",
    "        relative_error = np.sqrt(mse_error) / np.abs(U_fem_flat).mean()\n",
    "\n",
    "        # Calculate the relative percentage error\n",
    "        relative_percentage_error = (np.linalg.norm(U_pinn - U_fem_flat) / np.linalg.norm(U_fem_flat)) * 100\n",
    "\n",
    "        # Append the errors to the DataFrame\n",
    "        error_df = error_df.append({\n",
    "            'Step': step,\n",
    "            'MSE': mse_error,\n",
    "            'Relative_Error': relative_error,\n",
    "            'Relative_Percentage_Error': relative_percentage_error\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Save the errors DataFrame to a CSV file\n",
    "error_df.to_csv('pinn_errors.csv', index=False)\n",
    "print(\"Errors saved to pinn_errors.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the FEM results from the CSV file\n",
    "fem_results_path = './LCRM_sol.csv'\n",
    "fem_results = pd.read_csv(fem_results_path)\n",
    "\n",
    "# Flatten the FEM results for comparison\n",
    "U_fem_flat = fem_results.values.flatten()\n",
    "\n",
    "# Generate the meshgrid for the domain\n",
    "num_points = int(np.sqrt(len(U_fem_flat)))  # Assuming a square domain\n",
    "x = np.linspace(0, 100, num_points)\n",
    "y = np.linspace(0, 100, num_points)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "X_flat = X.flatten()\n",
    "Y_flat = Y.flatten()\n",
    "X_fem_tensor = torch.tensor(np.vstack([X_flat, Y_flat]).T, dtype=torch.float32).to(device)\n",
    "\n",
    "# Directory where the PINN models are saved\n",
    "pinn_models_dir = './40_8_1000_5000_1000_test_70000steps/stages/'\n",
    "\n",
    "# Initialize a DataFrame to store the errors\n",
    "error_df = pd.DataFrame(columns=['Step', 'MSE', 'Relative_Error', 'Relative_Percentage_Error'])\n",
    "\n",
    "# Loop through the saved models and calculate errors\n",
    "for filename in sorted(os.listdir(pinn_models_dir)):\n",
    "    if filename.endswith('.pth'):\n",
    "        try:\n",
    "            # Extract step number from filename, assuming it's formatted like \"pinn_model_step_{step}.pth\"\n",
    "            step = int(filename.split('_')[-1].split('.')[0])\n",
    "        except ValueError:\n",
    "            # Skip files that do not have a step number in their name\n",
    "            print(f\"Skipping file with unexpected name format: {filename}\")\n",
    "            continue\n",
    "\n",
    "        pinn_model_path = os.path.join(pinn_models_dir, filename)\n",
    "        pinn_model = torch.load(pinn_model_path, map_location=device)\n",
    "        pinn_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            U_pinn = pinn_model(X_fem_tensor).cpu().numpy().flatten()\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse_error = ((U_pinn - U_fem_flat) ** 2).mean()\n",
    "\n",
    "        # Calculate the relative error\n",
    "        relative_error = np.sqrt(mse_error) / np.abs(U_fem_flat).mean()\n",
    "\n",
    "        # Calculate the relative percentage error\n",
    "        relative_percentage_error = (np.linalg.norm(U_pinn - U_fem_flat) / np.linalg.norm(U_fem_flat)) * 100\n",
    "\n",
    "        # Append the errors to the DataFrame\n",
    "        error_df = error_df.append({\n",
    "            'Step': step,\n",
    "            'MSE': mse_error,\n",
    "            'Relative_Error': relative_error,\n",
    "            'Relative_Percentage_Error': relative_percentage_error\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Save the errors DataFrame to a CSV file\n",
    "error_df.to_csv('pinn_errors.csv', index=False)\n",
    "print(\"Errors saved to pinn_errors.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file with unexpected name format: final_pinn_model_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n",
      "C:\\Users\\88018\\AppData\\Local\\Temp\\ipykernel_13936\\1245683626.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  error_df = error_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors saved to pinn_errors.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the FEM results from the CSV file\n",
    "fem_results_path = './LCRM_sol.csv'\n",
    "fem_results = pd.read_csv(fem_results_path)\n",
    "\n",
    "# Flatten the FEM results for comparison\n",
    "U_fem_flat = fem_results.values.flatten()\n",
    "\n",
    "# Generate the meshgrid for the domain\n",
    "num_points = int(np.sqrt(len(U_fem_flat)))  # Assuming a square domain\n",
    "x = np.linspace(0, 100, num_points)\n",
    "y = np.linspace(0, 100, num_points)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "X_flat = X.flatten()\n",
    "Y_flat = Y.flatten()\n",
    "X_fem_tensor = torch.tensor(np.vstack([X_flat, Y_flat]).T, dtype=torch.float32).to(device)\n",
    "\n",
    "# Directory where the PINN models are saved\n",
    "pinn_models_dir = './40_8_500_1500_1000_test_35000steps/'\n",
    "\n",
    "# Initialize a DataFrame to store the errors\n",
    "error_df = pd.DataFrame(columns=['Step', 'MSE', 'Relative_Error', 'Relative_Percentage_Error'])\n",
    "\n",
    "# Loop through the saved models and calculate errors\n",
    "for filename in sorted(os.listdir(pinn_models_dir)):\n",
    "    if filename.endswith('.pth'):\n",
    "        try:\n",
    "            # Extract step number from filename, assuming it's formatted like \"pinn_model_step_{step}.pth\"\n",
    "            step = int(filename.split('_')[-1].split('.')[0])\n",
    "        except ValueError:\n",
    "            # Skip files that do not have a step number in their name\n",
    "            print(f\"Skipping file with unexpected name format: {filename}\")\n",
    "            continue\n",
    "\n",
    "        pinn_model_path = os.path.join(pinn_models_dir, filename)\n",
    "        pinn_model = torch.load(pinn_model_path, map_location=device)\n",
    "        pinn_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            U_pinn = pinn_model(X_fem_tensor).cpu().numpy().flatten()\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse_error = ((U_pinn - U_fem_flat) ** 2).mean()\n",
    "\n",
    "        # Calculate the relative error\n",
    "        relative_error = np.sqrt(mse_error) / np.abs(U_fem_flat).mean()\n",
    "\n",
    "        # Calculate the relative percentage error\n",
    "        relative_percentage_error = (np.linalg.norm(U_pinn - U_fem_flat) / np.linalg.norm(U_fem_flat)) * 100\n",
    "\n",
    "        # Append the errors to the DataFrame\n",
    "        error_df = error_df.append({\n",
    "            'Step': step,\n",
    "            'MSE': mse_error,\n",
    "            'Relative_Error': relative_error,\n",
    "            'Relative_Percentage_Error': relative_percentage_error\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Save the errors DataFrame to a CSV file\n",
    "error_df.to_csv(f'{pinn_models_dir}erros.csv', index=False)\n",
    "print(\"Errors saved to pinn_errors.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
